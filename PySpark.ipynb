{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PySpark Tutorial: Data Processing and Analysis\n",
        "\n",
        "## Overview\n",
        "This notebook covers fundamental PySpark concepts and operations for distributed data processing. PySpark is the Python API for Apache Spark, a powerful distributed computing framework designed for processing large-scale datasets.\n",
        "\n",
        "### Key Topics Covered:\n",
        "1. **SparkSession Initialization** - Entry point for Spark functionality\n",
        "2. **Data Loading** - Reading Parquet files\n",
        "3. **DataFrame Inspection** - Schema, columns, and statistics\n",
        "4. **Data Selection** - Choosing specific columns\n",
        "5. **Data Sorting** - Ordering data by criteria\n",
        "6. **Data Filtering** - Subsetting data based on conditions\n",
        "7. **Data Cleaning** - Handling missing values\n",
        "8. **Feature Engineering** - Creating new columns from existing data\n",
        "9. **Column Renaming** - Restructuring DataFrame columns\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5_dBir1JrrS",
        "outputId": "7002954a-f2b1-42f4-b524-a8ecb12dbd0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: py4j<0.10.9.10,>=0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark package\n",
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "NYw0mtutM9jF",
        "outputId": "9c4f21eb-d8eb-4c08-87ef-97e36125460b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://dd3043ccad8a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v4.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>SparkApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7875d8c24b60>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize SparkSession - the entry point for Spark functionality\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create or get an existing SparkSession with the name 'SparkApp'\n",
        "spark = SparkSession.builder.appName(\"SparkApp\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWR04v3lNnvc"
      },
      "outputs": [],
      "source": [
        "# Load data from a Parquet file into a Spark DataFrame\n",
        "# Parquet is a columnar storage format optimized for analytical queries\n",
        "spark_df = spark.read.parquet(\"/content/yellow_tripdata_2025-01.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBwcvb4INnx8",
        "outputId": "daa90f69-85db-464e-b428-eb01d6eb025a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3475226"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count the total number of rows in the DataFrame\n",
        "# Action: This triggers Spark to compute and return the result\n",
        "spark_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N1M2wAZNn0O",
        "outputId": "937d124b-97a8-4271-b9fb-a552ffe11cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|       1| 2025-01-01 00:18:38|  2025-01-01 00:26:59|              1|          1.6|         1|                 N|         229|         237|           1|       10.0|  3.5|    0.5|       3.0|         0.0|                  1.0|        18.0|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:32:40|  2025-01-01 00:35:13|              1|          0.5|         1|                 N|         236|         237|           1|        5.1|  3.5|    0.5|      2.02|         0.0|                  1.0|       12.12|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:44:04|  2025-01-01 00:46:01|              1|          0.6|         1|                 N|         141|         141|           1|        5.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        12.1|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:14:27|  2025-01-01 00:20:01|              3|         0.52|         1|                 N|         244|         244|           2|        7.2|  1.0|    0.5|       0.0|         0.0|                  1.0|         9.7|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:21:34|  2025-01-01 00:25:06|              3|         0.66|         1|                 N|         244|         116|           2|        5.8|  1.0|    0.5|       0.0|         0.0|                  1.0|         8.3|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:48:24|  2025-01-01 01:08:26|              2|         2.63|         1|                 N|         239|          68|           2|       19.1|  1.0|    0.5|       0.0|         0.0|                  1.0|        24.1|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:14:47|  2025-01-01 00:16:15|              0|          0.4|         1|                 N|         170|         170|           1|        4.4|  3.5|    0.5|      2.35|         0.0|                  1.0|       11.75|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:39:27|  2025-01-01 00:51:51|              0|          1.6|         1|                 N|         234|         148|           1|       12.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        19.1|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:53:43|  2025-01-01 01:13:23|              0|          2.8|         1|                 N|         148|         170|           1|       19.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        27.1|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:00:02|  2025-01-01 00:09:36|              1|         1.71|         1|                 N|         237|         262|           2|       11.4|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.4|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:20:28|  2025-01-01 00:28:04|              1|         2.29|         1|                 N|         237|          75|           2|       11.4|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.4|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:33:58|  2025-01-01 00:37:23|              1|         0.56|         1|                 N|         263|         236|           1|        5.8|  1.0|    0.5|      2.16|         0.0|                  1.0|       12.96|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:42:40|  2025-01-01 00:55:38|              3|         1.99|         1|                 N|         236|         151|           2|       14.2|  1.0|    0.5|       0.0|         0.0|                  1.0|        19.2|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:30:07|  2025-01-01 00:36:48|              1|          1.1|         1|                 N|         229|         141|           2|        7.9|  3.5|    0.5|       0.0|         0.0|                  1.0|        12.9|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:39:55|  2025-01-01 01:13:59|              1|          3.2|         1|                 N|         141|         113|           1|       26.1|  3.5|    0.5|       7.8|         0.0|                  1.0|        38.9|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:16:54|  2025-01-01 00:35:12|              3|          2.5|         1|                 N|         158|         170|           2|       17.7|  3.5|    0.5|       0.0|         0.0|                  1.0|        22.7|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:43:10|  2025-01-01 01:00:03|              1|          1.9|         1|                 N|         164|         229|           1|       16.3|  3.5|    0.5|      4.25|         0.0|                  1.0|       25.55|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:01:41|  2025-01-01 00:07:14|              1|         0.71|         1|                 N|          79|         107|           2|       -7.2| -1.0|   -0.5|      3.66|         0.0|                 -1.0|       -8.54|                -2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:01:41|  2025-01-01 00:07:14|              1|         0.71|         1|                 N|          79|         107|           2|        7.2|  1.0|    0.5|       0.0|         0.0|                  1.0|        12.2|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:33:12|  2025-01-01 00:50:14|              2|          1.2|         1|                 N|         246|          90|           1|       15.6|  3.5|    0.5|       0.0|         0.0|                  1.0|        20.6|                 2.5|        0.0|               0.0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Display the first 20 rows of the DataFrame\n",
        "# This is useful for a quick visual inspection of the data\n",
        "spark_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44771f22"
      },
      "source": [
        "## 1. SparkSession Initialization\n",
        "\n",
        "**What is SparkSession?**\n",
        "- The entry point for all Spark functionality in PySpark\n",
        "- Represents the connection to a Spark cluster\n",
        "- Enables you to read data, run SQL queries, and perform distributed computations\n",
        "\n",
        "**Key Properties:**\n",
        "- `appName`: Name of your Spark application (useful for tracking in cluster UIs)\n",
        "- Lazily creates a session on first use\n",
        "- Can be reused throughout your script\n",
        "\n",
        "**Why it's important:**\n",
        "All data processing operations in Spark depend on an active SparkSession instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e915d882"
      },
      "source": [
        "## 2. Reading Data with Parquet Files\n",
        "\n",
        "**What is Parquet?**\n",
        "- A columnar storage format developed by Apache\n",
        "- Optimized for analytical queries and data warehousing\n",
        "- Stores data in a compressed format, reducing storage space\n",
        "- Faster than row-based formats like CSV for analytical operations\n",
        "\n",
        "**Why use Parquet?**\n",
        "- Excellent compression (reduces data size by 70-90%)\n",
        "- Efficient column-oriented queries (only reads needed columns)\n",
        "- Preserves data types and schema information\n",
        "- Ideal for big data analytics\n",
        "\n",
        "**The `spark.read.parquet()` method:**\n",
        "- Reads Parquet files into a Spark DataFrame\n",
        "- Automatically infers the schema from the file\n",
        "- Returns a distributed DataFrame object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e13208b"
      },
      "source": [
        "## 3. DataFrame Row Counting\n",
        "\n",
        "**The `count()` Method:**\n",
        "- Returns the total number of rows in the DataFrame\n",
        "- This is an **Action** in Spark - it triggers actual computation\n",
        "- Useful for understanding dataset size and volume\n",
        "\n",
        "**Actions vs Transformations:**\n",
        "- **Actions**: Execute computations and return results (count, show, collect, write)\n",
        "- **Transformations**: Create new DataFrames from existing ones (select, filter, sort) - lazy evaluation\n",
        "\n",
        "**Performance Note:**\n",
        "- For very large datasets, counting can take significant time\n",
        "- Spark must read and process all partitions to get an accurate count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ddf756d"
      },
      "source": [
        "## 4. Viewing DataFrame Data\n",
        "\n",
        "**The `show()` Method:**\n",
        "- Displays the first 20 rows of the DataFrame (by default)\n",
        "- Returns data in a tabular format for easy reading\n",
        "- Useful for quick data inspection and verification\n",
        "- Only evaluates what's needed (truncates long strings)\n",
        "\n",
        "**Parameters:**\n",
        "- `n`: Number of rows to display (default: 20)\n",
        "- `truncate`: Max column width before truncating (default: True)\n",
        "- `vertical`: Display rows vertically instead of horizontally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42307b95"
      },
      "source": [
        "## 5. Inspecting DataFrame Columns\n",
        "\n",
        "**The `columns` Property:**\n",
        "- Returns a Python list of all column names in the DataFrame\n",
        "- Useful for understanding what fields are available\n",
        "- Helps with programmatic column access and validation\n",
        "- Returns column names in the order they appear in the schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5a786bd"
      },
      "source": [
        "## 6. Understanding DataFrame Schema\n",
        "\n",
        "**The `printSchema()` Method:**\n",
        "- Displays the schema in a tree-like format\n",
        "- Shows column names, data types, and nullable properties\n",
        "- Essential for understanding data structure and types\n",
        "- Helps identify potential data type mismatches\n",
        "\n",
        "**What's in the Schema:**\n",
        "- Column name\n",
        "- Data type (String, Integer, Double, Boolean, etc.)\n",
        "- Nullable flag (can column contain NULL values?)\n",
        "- Nested structures for complex data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d2b3cc6"
      },
      "source": [
        "## 7. Accessing Schema as an Object\n",
        "\n",
        "**The `schema` Property:**\n",
        "- Returns a `StructType` object representing the DataFrame schema\n",
        "- Allows programmatic access to schema details\n",
        "- Useful when you need to manipulate or inspect schema in code\n",
        "- Can be serialized/deserialized for schema management\n",
        "\n",
        "**Schema Inspection Benefits:**\n",
        "- Extract field information programmatically\n",
        "- Validate data types before processing\n",
        "- Generate schema-aware code dynamically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6a4883f"
      },
      "source": [
        "## 8. Statistical Summary of Data\n",
        "\n",
        "**The `describe()` Method:**\n",
        "- Computes descriptive statistics for numerical columns\n",
        "- Returns count, mean, standard deviation, min, and max values\n",
        "- Called with `.show()` to display results\n",
        "\n",
        "**Statistics Provided:**\n",
        "- **count**: Non-null values in each column\n",
        "- **mean**: Average value\n",
        "- **stddev**: Standard deviation (data spread)\n",
        "- **min**: Minimum value\n",
        "- **max**: Maximum value\n",
        "\n",
        "**Use Cases:**\n",
        "- Quick data quality checks\n",
        "- Identify outliers and data ranges\n",
        "- Understand distribution of numerical data\n",
        "- Detect potential data entry errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SAc0x1VNn2f",
        "outputId": "2263b90e-8ea9-42c4-8285-67519d9aec91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['VendorID',\n",
              " 'tpep_pickup_datetime',\n",
              " 'tpep_dropoff_datetime',\n",
              " 'passenger_count',\n",
              " 'trip_distance',\n",
              " 'RatecodeID',\n",
              " 'store_and_fwd_flag',\n",
              " 'PULocationID',\n",
              " 'DOLocationID',\n",
              " 'payment_type',\n",
              " 'fare_amount',\n",
              " 'extra',\n",
              " 'mta_tax',\n",
              " 'tip_amount',\n",
              " 'tolls_amount',\n",
              " 'improvement_surcharge',\n",
              " 'total_amount',\n",
              " 'congestion_surcharge',\n",
              " 'Airport_fee',\n",
              " 'cbd_congestion_fee']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all column names as a list\n",
        "spark_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXKqkYI1OHQr",
        "outputId": "d6afe88d-d0b4-4f63-e6a4-86b6206d21b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: integer (nullable = true)\n",
            " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
            " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
            " |-- passenger_count: long (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- RatecodeID: long (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- PULocationID: integer (nullable = true)\n",
            " |-- DOLocationID: integer (nullable = true)\n",
            " |-- payment_type: long (nullable = true)\n",
            " |-- fare_amount: double (nullable = true)\n",
            " |-- extra: double (nullable = true)\n",
            " |-- mta_tax: double (nullable = true)\n",
            " |-- tip_amount: double (nullable = true)\n",
            " |-- tolls_amount: double (nullable = true)\n",
            " |-- improvement_surcharge: double (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            " |-- congestion_surcharge: double (nullable = true)\n",
            " |-- Airport_fee: double (nullable = true)\n",
            " |-- cbd_congestion_fee: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the schema of the DataFrame in a tree format\n",
        "# Shows all column names, data types, and nullable properties\n",
        "spark_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciOC6FTnNn5p",
        "outputId": "1d89035c-5b47-4534-a512-99df678db199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampNTZType(), True), StructField('tpep_dropoff_datetime', TimestampNTZType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('Airport_fee', DoubleType(), True), StructField('cbd_congestion_fee', DoubleType(), True)])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the schema as a StructType object for programmatic access\n",
        "spark_df.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5iM00tdOOYB",
        "outputId": "c6c30a62-5fe0-405e-df67-d9111690a277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+-------------------+\n",
            "|summary|           VendorID|   passenger_count|     trip_distance|        RatecodeID|store_and_fwd_flag|     PULocationID|      DOLocationID|      payment_type|       fare_amount|             extra|            mta_tax|        tip_amount|      tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|        Airport_fee| cbd_congestion_fee|\n",
            "+-------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+-------------------+\n",
            "|  count|            3475226|           2935077|           3475226|           2935077|           2935077|          3475226|           3475226|           3475226|           3475226|           3475226|            3475226|           3475226|           3475226|              3475226|           3475226|             2935077|            2935077|            3475226|\n",
            "|   mean| 1.7854283433652949|1.2978589658806226|5.8551261788432925| 2.482534529758504|              NULL|165.1915757421244|164.12517689497028|1.0366229419324096|17.081802760456707| 1.317736691081386| 0.4780990502488183| 2.959812786275976|0.4493081025511922|   0.9547945658785998|25.611291697295062|   2.225237191392253|0.12391105923285829|0.48340928043240927|\n",
            "| stddev|0.42632822130544934| 0.750750275480471|  564.601599634634|11.632772004033159|              NULL|64.52948262355366| 69.40168629828565|0.7013334099485161| 463.4729178173049|1.8615086824178564|0.13746226502954273|3.7796811536124078| 2.002581813990847|   0.2781937753492546| 463.6584784502283|  0.9039932093176659|0.47250898141472714|0.36193065974945887|\n",
            "|    min|                  1|                 0|               0.0|                 1|                 N|                1|                 1|                 0|            -900.0|              -7.5|               -0.5|             -86.0|           -126.94|                 -1.0|            -901.0|                -2.5|              -1.75|              -0.75|\n",
            "|    max|                  7|                 9|         276423.57|                99|                 Y|              265|               265|                 5|         863372.12|              15.0|               10.5|             400.0|            170.94|                  1.0|         863380.37|                 2.5|               6.75|               0.75|\n",
            "+-------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display descriptive statistics (count, mean, stddev, min, max) for numerical columns\n",
        "spark_df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Data Transformation Operations\n",
        "\n",
        "### 9. Column Selection (Projection)\n",
        "\n",
        "**The `select()` Method:**\n",
        "- Selects specific columns from a DataFrame\n",
        "- Returns a new DataFrame with only chosen columns\n",
        "- Reduces memory footprint by removing unnecessary data\n",
        "- Can be used with column names or Column objects\n",
        "\n",
        "**Syntax:**\n",
        "- `df.select(['col1', 'col2', ...])` - using list of strings\n",
        "- `df.select('col1', 'col2')` - using variable arguments\n",
        "- `df.select(col('col1'), col('col2'))` - using Column objects\n",
        "\n",
        "**Benefits:**\n",
        "- Improves query performance (only processes needed columns)\n",
        "- Simplifies data by removing irrelevant fields\n",
        "- Foundation for feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoORe1n5OVBz",
        "outputId": "6e54266a-b912-40e7-f7ff-560b64467dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------------+\n",
            "|fare_amount|passenger_count|\n",
            "+-----------+---------------+\n",
            "|       10.0|              1|\n",
            "|        5.1|              1|\n",
            "|        5.1|              1|\n",
            "|        7.2|              3|\n",
            "|        5.8|              3|\n",
            "|       19.1|              2|\n",
            "|        4.4|              0|\n",
            "|       12.1|              0|\n",
            "|       19.1|              0|\n",
            "|       11.4|              1|\n",
            "|       11.4|              1|\n",
            "|        5.8|              1|\n",
            "|       14.2|              3|\n",
            "|        7.9|              1|\n",
            "|       26.1|              1|\n",
            "|       17.7|              3|\n",
            "|       16.3|              1|\n",
            "|       -7.2|              1|\n",
            "|        7.2|              1|\n",
            "|       15.6|              2|\n",
            "+-----------+---------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Select only specific columns: fare_amount and passenger_count\n",
        "# This creates a new DataFrame with just these two columns\n",
        "spark_df.select(['fare_amount','passenger_count']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E1OUl_yPpFY",
        "outputId": "ad74415a-dfe2-4f0f-afa0-2a775f85859a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|       2| 2025-01-07 19:12:25|  2025-01-07 19:14:04|              1|          0.1|         5|                 N|         226|         226|           3|     -900.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -901.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-19 23:52:08|  2025-01-19 23:52:17|              1|          0.0|         5|                 N|         265|         265|           4|     -850.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -851.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 23:13:43|  2025-01-02 01:47:38|              1|       132.27|         4|                 N|         132|         265|           4|     -826.2| -1.0|    0.0|       0.0|      -35.44|                 -1.0|     -865.39|                 0.0|      -1.75|               0.0|\n",
            "|       2| 2025-01-01 13:47:30|  2025-01-01 13:47:40|              1|          0.0|         5|                 N|         265|         265|           4|     -700.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -701.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 13:56:20|  2025-01-01 13:56:24|              1|          0.0|         5|                 N|         265|         265|           4|     -700.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -701.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-05 21:51:52|  2025-01-05 21:52:14|              1|          0.0|         5|                 N|          74|          74|           2|     -700.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -701.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-14 02:08:52|  2025-01-14 02:10:20|              1|         0.35|         5|                 N|         230|          48|           4|     -700.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|     -704.25|                -2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-16 08:02:27|  2025-01-16 08:03:02|              4|          0.0|         5|                 N|         132|         132|           4|     -700.0|  0.0|    0.0|      50.0|         0.0|                 -1.0|     -652.75|                 0.0|      -1.75|               0.0|\n",
            "|       2| 2025-01-11 09:50:17|  2025-01-11 12:43:04|              4|        78.94|         4|                 N|         261|         261|           4|     -634.4|  0.0|   -0.5|      20.0|      -14.06|                 -1.0|     -633.21|                -2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-26 11:50:22|  2025-01-26 11:50:28|              3|          0.0|         5|                 N|         138|         138|           2|     -600.0| -5.0|    0.0|       0.0|         0.0|                 -1.0|     -607.75|                 0.0|      -1.75|               0.0|\n",
            "|       2| 2025-01-05 14:24:08|  2025-01-05 14:24:47|              1|          0.0|         5|                 N|         242|         242|           3|     -600.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -601.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-07 22:50:46|  2025-01-08 00:39:35|              1|        87.92|         4|                 N|         132|         265|           4|     -595.2| -1.0|    0.0|      20.0|       -6.94|                 -1.0|     -585.89|                 0.0|      -1.75|               0.0|\n",
            "|       2| 2025-01-09 12:56:34|  2025-01-09 14:54:51|              2|        81.14|         4|                 N|         132|         265|           3|     -579.8|  0.0|   -0.5|       0.0|      -35.06|                 -1.0|     -616.36|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-12 11:52:37|  2025-01-12 14:23:10|              1|       131.88|         5|                 N|         132|         265|           2|     -550.0|  0.0|    0.0|      15.0|         0.0|                 -1.0|     -537.75|                 0.0|      -1.75|               0.0|\n",
            "|       2| 2025-01-23 15:07:01|  2025-01-23 17:10:43|              1|        86.55|         4|                 N|         132|         265|           2|     -541.3|  0.0|   -0.5|       0.0|       -6.94|                 -1.0|     -551.49|                 0.0|      -1.75|               0.0|\n",
            "|       2| 2025-01-19 17:05:05|  2025-01-19 19:06:22|              1|        86.88|         4|                 N|         132|         265|           4|     -502.8|  0.0|    0.0|      10.0|      -45.94|                 -1.0|     -541.49|                 0.0|      -1.75|               0.0|\n",
            "|       2| 2025-01-27 10:02:37|  2025-01-27 10:02:53|              1|          0.0|         5|                 N|         265|         265|           4|     -500.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -501.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-14 09:18:16|  2025-01-14 09:18:29|              1|          0.0|         5|                 N|         198|         198|           3|     -500.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -501.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-28 10:47:58|  2025-01-28 10:48:02|              1|          0.0|         5|                 N|         260|         260|           3|     -499.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -500.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-28 11:00:35|  2025-01-28 11:00:39|              1|          0.0|         5|                 N|         260|         260|           3|     -499.0|  0.0|    0.0|       0.0|         0.0|                 -1.0|      -500.0|                 0.0|        0.0|               0.0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Sort the DataFrame by a single column in ascending order (default)\n",
        "# The sort() method is a transformation that creates a new sorted DataFrame\n",
        "spark_df.sort('fare_amount').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 10. Sorting Data\n",
        "\n",
        "**The `sort()` Method:**\n",
        "- Arranges rows based on one or more column values\n",
        "- Returns a new sorted DataFrame\n",
        "- Default order is ascending (smallest to largest)\n",
        "- Can sort by multiple columns with different orders\n",
        "\n",
        "**Parameters:**\n",
        "- Column name or list of column names\n",
        "- `ascending`: Boolean or list of booleans for sort order\n",
        "- Multiple sort criteria applied in order\n",
        "\n",
        "**Use Cases:**\n",
        "- Ranking data by values\n",
        "- Finding top N or bottom N records\n",
        "- Organizing data for presentation\n",
        "- Preparing data for time-series analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e7ft4KzQTnD",
        "outputId": "98cfbad0-49cd-4ad9-e0b1-ec626a340d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|       1| 2025-01-20 12:07:18|  2025-01-20 12:12:42|              1|          1.6|         1|                 N|         138|           8|           4|  863372.12| 6.75|    0.5|       0.0|         0.0|                  1.0|   863380.37|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-16 12:23:14|  2025-01-17 14:41:56|              1|       255.33|         4|                 N|         161|         265|           2|     2450.9|  0.0|    0.0|       0.0|       54.06|                  1.0|     2506.71|                 0.0|        0.0|              0.75|\n",
            "|       2| 2025-01-21 05:17:57|  2025-01-21 08:19:45|              1|       188.88|         4|                 N|         247|         265|           2|     1309.2|  1.0|    0.5|       0.0|         0.0|                  1.0|      1311.7|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-26 00:04:04|  2025-01-26 00:04:42|              4|          0.0|         5|                 N|         142|         142|           2|      950.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       953.5|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-26 00:22:47|  2025-01-26 00:22:55|              4|          0.0|         5|                 N|         226|         226|           2|      950.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       951.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-26 00:24:25|  2025-01-26 00:24:35|              4|          0.0|         5|                 N|         226|         226|           2|      950.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       951.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-15 19:14:42|  2025-01-15 21:46:13|              1|       143.54|         4|                 N|         132|         265|           1|      936.8|  2.5|    0.0|       0.0|        27.0|                  1.0|      969.05|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-26 00:00:56|  2025-01-26 00:01:06|              4|          0.0|         5|                 N|         142|         142|           2|      900.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       903.5|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-07 19:12:25|  2025-01-07 19:14:04|              1|          0.1|         5|                 N|         226|         226|           3|      900.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       901.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-25 23:56:58|  2025-01-25 23:57:06|              4|          0.0|         5|                 N|         142|         142|           2|     899.99|  0.0|    0.0|       0.0|         0.0|                  1.0|      903.49|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-25 23:58:50|  2025-01-25 23:59:00|              4|          0.0|         5|                 N|         142|         142|           2|     899.99|  0.0|    0.0|       0.0|         0.0|                  1.0|      903.49|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-13 17:19:58|  2025-01-13 20:07:08|              1|        133.3|         5|                 N|         132|         265|           1|     893.75| 1.75|    0.0|       0.0|         0.0|                  1.0|       896.5|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-19 23:52:08|  2025-01-19 23:52:17|              1|          0.0|         5|                 N|         265|         265|           4|      850.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       851.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 23:13:43|  2025-01-02 01:47:38|              1|       132.27|         4|                 N|         132|         265|           4|      826.2|  1.0|    0.0|       0.0|       35.44|                  1.0|      865.39|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-26 19:25:41|  2025-01-26 19:25:56|              1|          0.0|         5|                 N|         216|         216|           1|      800.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       801.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 12:53:37|  2025-01-01 15:25:57|              1|       119.66|         4|                 N|         101|         265|           2|      773.0|  0.0|    0.5|       0.0|       20.32|                  1.0|      794.82|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-16 08:02:27|  2025-01-16 08:03:02|              4|          0.0|         5|                 N|         132|         132|           4|      700.0|  0.0|    0.0|       0.0|         0.0|                  1.0|      702.75|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 13:47:30|  2025-01-01 13:47:40|              1|          0.0|         5|                 N|         265|         265|           2|      700.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       701.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 13:56:20|  2025-01-01 13:56:24|              1|          0.0|         5|                 N|         265|         265|           2|      700.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       701.0|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-05 21:51:52|  2025-01-05 21:52:14|              1|          0.0|         5|                 N|          74|          74|           2|      700.0|  0.0|    0.0|       0.0|         0.0|                  1.0|       701.0|                 0.0|        0.0|               0.0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Sort by multiple columns in descending order\n",
        "# Sorts first by fare_amount (descending), then by passenger_count (descending)\n",
        "spark_df.sort(['fare_amount',\"passenger_count\"], ascending = [False,False]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 11. Filtering Data (Selection)\n",
        "\n",
        "**The `filter()` Method:**\n",
        "- Selects rows that satisfy a condition\n",
        "- Returns a new DataFrame with only matching rows\n",
        "- Critical for data cleaning and subsetting\n",
        "- Conditions can use SQL syntax or PySpark expressions\n",
        "\n",
        "**Filter Syntax Options:**\n",
        "1. **SQL String**: `df.filter('column > 100')`\n",
        "2. **PySpark Expression**: `df.filter(df['column'] > 100)`\n",
        "3. **Column Object**: `df.filter(col('column') > 100)`\n",
        "\n",
        "**Combining Conditions:**\n",
        "- AND operator: `&` (not `and`)\n",
        "- OR operator: `|` (not `or`)\n",
        "- NOT operator: `~` (not `not`)\n",
        "- Must wrap conditions in parentheses when combining\n",
        "\n",
        "**Performance Considerations:**\n",
        "- Filter early to reduce data size\n",
        "- More selective filters improve performance\n",
        "- Spark optimizes filter operations automatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga5EAodHQzxQ",
        "outputId": "4eb319a7-b585-4ae7-c6cb-875db1700af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|       1| 2025-01-01 00:51:41|  2025-01-01 01:06:26|              1|          7.2|         1|                 N|         132|          95|           1|       29.6| 2.75|    0.5|      6.75|         0.0|                  1.0|        40.6|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:55:44|  2025-01-01 01:27:41|              1|        14.84|         1|                 N|         132|          89|           1|       59.0|  1.0|    0.5|      12.3|         0.0|                  1.0|       75.55|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:02:20|  2025-01-01 00:15:55|              1|         4.55|         1|                 N|         138|         146|           1|       19.8|  6.0|    0.5|      8.19|         0.0|                  1.0|       37.24|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:08:07|  2025-01-01 00:13:06|              1|         1.61|         1|                 N|         138|         138|           2|        9.3|  6.0|    0.5|       0.0|         0.0|                  1.0|       18.55|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:24:51|  2025-01-01 00:42:52|              2|         8.66|         1|                 N|         138|         256|           1|       35.2|  6.0|    0.5|      4.44|         0.0|                  1.0|       48.89|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:11:59|  2025-01-01 00:48:37|              2|         9.17|         1|                 N|         138|         186|           1|       48.5|  6.0|    0.5|     13.09|        6.94|                  1.0|       80.28|                 2.5|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:39:59|  2025-01-01 01:00:37|              1|         7.78|         1|                 N|         138|          36|           1|       33.8|  6.0|    0.5|      8.26|         0.0|                  1.0|       51.31|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:32:51|  2025-01-01 00:54:01|              1|         9.58|         1|                 N|         132|          77|           2|       39.4|  1.0|    0.5|       0.0|         0.0|                  1.0|       43.65|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:03:00|  2025-01-01 00:25:10|              2|         10.4|         1|                 N|         138|         162|           1|       40.8|10.25|    0.5|       0.0|        6.94|                  1.0|       59.49|                 2.5|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:09:22|  2025-01-01 00:20:00|              1|         6.09|         1|                 N|         138|         112|           2|       24.7|  6.0|    0.5|       0.0|         0.0|                  1.0|       33.95|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:23:05|  2025-01-01 00:56:38|              1|         22.0|         1|                 N|         132|         241|           2|       80.7| 2.75|    0.5|       0.0|        6.94|                  1.0|       91.89|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:17:04|  2025-01-01 00:39:02|              1|         9.82|         1|                 N|         132|         122|           2|       40.1|  1.0|    0.5|       0.0|         0.0|                  1.0|       44.35|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:01:41|  2025-01-01 00:15:29|              1|         7.15|         1|                 N|         138|          80|           1|       29.6|  6.0|    0.5|      40.0|         0.0|                  1.0|       78.85|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:36:08|  2025-01-01 00:54:52|              4|        11.86|         1|                 N|         138|         241|           1|       45.0|  6.0|    0.5|      30.0|        6.94|                  1.0|       91.19|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:03:30|  2025-01-01 00:16:37|              3|         5.81|         1|                 N|          70|          95|           1|       24.7|  6.0|    0.5|      6.44|         0.0|                  1.0|       40.39|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:39:58|  2025-01-01 01:01:26|              1|         8.02|         1|                 N|         138|         112|           1|       35.2|  6.0|    0.5|      8.54|         0.0|                  1.0|       52.99|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:24:10|  2025-01-01 00:32:36|              1|          3.2|         1|                 N|         138|           7|           1|       14.9| 7.75|    0.5|       6.0|         0.0|                  1.0|       30.15|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:47:18|  2025-01-01 01:00:47|              2|          8.9|         1|                 N|         138|         140|           1|       34.5|10.25|    0.5|      5.32|        6.94|                  1.0|       58.51|                 2.5|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:18:04|  2025-01-01 00:30:56|              1|         7.41|         1|                 N|         138|         217|           1|       30.3|  6.0|    0.5|      7.56|         0.0|                  1.0|       47.11|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:13:00|  2025-01-01 00:30:33|              1|         7.64|         1|                 N|         138|          36|           1|       32.4|  6.0|    0.5|       4.0|         0.0|                  1.0|       45.65|                 0.0|       1.75|               0.0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Filter for rows where Airport_fee is greater than 0\n",
        "# Uses SQL string syntax for the filter condition\n",
        "spark_df.filter('Airport_fee >0').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHxleIR8Repi",
        "outputId": "47725062-ff9b-4373-aeb8-c7ae08c55799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|       1| 2025-01-01 00:18:38|  2025-01-01 00:26:59|              1|          1.6|         1|                 N|         229|         237|           1|       10.0|  3.5|    0.5|       3.0|         0.0|                  1.0|        18.0|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:32:40|  2025-01-01 00:35:13|              1|          0.5|         1|                 N|         236|         237|           1|        5.1|  3.5|    0.5|      2.02|         0.0|                  1.0|       12.12|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:44:04|  2025-01-01 00:46:01|              1|          0.6|         1|                 N|         141|         141|           1|        5.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        12.1|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:14:27|  2025-01-01 00:20:01|              3|         0.52|         1|                 N|         244|         244|           2|        7.2|  1.0|    0.5|       0.0|         0.0|                  1.0|         9.7|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:21:34|  2025-01-01 00:25:06|              3|         0.66|         1|                 N|         244|         116|           2|        5.8|  1.0|    0.5|       0.0|         0.0|                  1.0|         8.3|                 0.0|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:48:24|  2025-01-01 01:08:26|              2|         2.63|         1|                 N|         239|          68|           2|       19.1|  1.0|    0.5|       0.0|         0.0|                  1.0|        24.1|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:14:47|  2025-01-01 00:16:15|              0|          0.4|         1|                 N|         170|         170|           1|        4.4|  3.5|    0.5|      2.35|         0.0|                  1.0|       11.75|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:39:27|  2025-01-01 00:51:51|              0|          1.6|         1|                 N|         234|         148|           1|       12.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        19.1|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:53:43|  2025-01-01 01:13:23|              0|          2.8|         1|                 N|         148|         170|           1|       19.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        27.1|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:20:28|  2025-01-01 00:28:04|              1|         2.29|         1|                 N|         237|          75|           2|       11.4|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.4|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:33:58|  2025-01-01 00:37:23|              1|         0.56|         1|                 N|         263|         236|           1|        5.8|  1.0|    0.5|      2.16|         0.0|                  1.0|       12.96|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:42:40|  2025-01-01 00:55:38|              3|         1.99|         1|                 N|         236|         151|           2|       14.2|  1.0|    0.5|       0.0|         0.0|                  1.0|        19.2|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:30:07|  2025-01-01 00:36:48|              1|          1.1|         1|                 N|         229|         141|           2|        7.9|  3.5|    0.5|       0.0|         0.0|                  1.0|        12.9|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:39:55|  2025-01-01 01:13:59|              1|          3.2|         1|                 N|         141|         113|           1|       26.1|  3.5|    0.5|       7.8|         0.0|                  1.0|        38.9|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:16:54|  2025-01-01 00:35:12|              3|          2.5|         1|                 N|         158|         170|           2|       17.7|  3.5|    0.5|       0.0|         0.0|                  1.0|        22.7|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:43:10|  2025-01-01 01:00:03|              1|          1.9|         1|                 N|         164|         229|           1|       16.3|  3.5|    0.5|      4.25|         0.0|                  1.0|       25.55|                 2.5|        0.0|               0.0|\n",
            "|       1| 2025-01-01 00:33:12|  2025-01-01 00:50:14|              2|          1.2|         1|                 N|         246|          90|           1|       15.6|  3.5|    0.5|       0.0|         0.0|                  1.0|        20.6|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:34:40|  2025-01-01 00:51:19|              2|         1.19|         1|                 N|         246|         170|           1|       14.9|  1.0|    0.5|      3.98|         0.0|                  1.0|       23.88|                 2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:55:54|  2025-01-01 01:00:38|              1|         0.69|         1|                 N|         137|         233|           4|       -6.5| -1.0|   -0.5|       0.0|         0.0|                 -1.0|       -11.5|                -2.5|        0.0|               0.0|\n",
            "|       2| 2025-01-01 00:55:54|  2025-01-01 01:00:38|              1|         0.69|         1|                 N|         137|         233|           4|        6.5|  1.0|    0.5|       0.0|         0.0|                  1.0|        11.5|                 2.5|        0.0|               0.0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Filter for rides where pickup time is after a specific datetime\n",
        "# Uses PySpark expression syntax with column reference\n",
        "spark_df.filter(spark_df['tpep_pickup_datetime']>'2025-01-01 00:11:59').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoSIytQyRqhI",
        "outputId": "0404e815-041e-49f9-f2a2-db556b9d9fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "|       1| 2025-01-01 00:51:41|  2025-01-01 01:06:26|              1|          7.2|         1|                 N|         132|          95|           1|       29.6| 2.75|    0.5|      6.75|         0.0|                  1.0|        40.6|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:55:44|  2025-01-01 01:27:41|              1|        14.84|         1|                 N|         132|          89|           1|       59.0|  1.0|    0.5|      12.3|         0.0|                  1.0|       75.55|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:24:51|  2025-01-01 00:42:52|              2|         8.66|         1|                 N|         138|         256|           1|       35.2|  6.0|    0.5|      4.44|         0.0|                  1.0|       48.89|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:39:59|  2025-01-01 01:00:37|              1|         7.78|         1|                 N|         138|          36|           1|       33.8|  6.0|    0.5|      8.26|         0.0|                  1.0|       51.31|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:32:51|  2025-01-01 00:54:01|              1|         9.58|         1|                 N|         132|          77|           2|       39.4|  1.0|    0.5|       0.0|         0.0|                  1.0|       43.65|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:23:05|  2025-01-01 00:56:38|              1|         22.0|         1|                 N|         132|         241|           2|       80.7| 2.75|    0.5|       0.0|        6.94|                  1.0|       91.89|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:17:04|  2025-01-01 00:39:02|              1|         9.82|         1|                 N|         132|         122|           2|       40.1|  1.0|    0.5|       0.0|         0.0|                  1.0|       44.35|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:36:08|  2025-01-01 00:54:52|              4|        11.86|         1|                 N|         138|         241|           1|       45.0|  6.0|    0.5|      30.0|        6.94|                  1.0|       91.19|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:39:58|  2025-01-01 01:01:26|              1|         8.02|         1|                 N|         138|         112|           1|       35.2|  6.0|    0.5|      8.54|         0.0|                  1.0|       52.99|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:24:10|  2025-01-01 00:32:36|              1|          3.2|         1|                 N|         138|           7|           1|       14.9| 7.75|    0.5|       6.0|         0.0|                  1.0|       30.15|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:47:18|  2025-01-01 01:00:47|              2|          8.9|         1|                 N|         138|         140|           1|       34.5|10.25|    0.5|      5.32|        6.94|                  1.0|       58.51|                 2.5|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:18:04|  2025-01-01 00:30:56|              1|         7.41|         1|                 N|         138|         217|           1|       30.3|  6.0|    0.5|      7.56|         0.0|                  1.0|       47.11|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:13:00|  2025-01-01 00:30:33|              1|         7.64|         1|                 N|         138|          36|           1|       32.4|  6.0|    0.5|       4.0|         0.0|                  1.0|       45.65|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:16:58|  2025-01-01 00:28:36|              1|         6.59|         1|                 N|         138|          95|           1|       26.1|  6.0|    0.5|     10.08|         0.0|                  1.0|       45.43|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:49:26|  2025-01-01 01:14:47|              1|        12.15|         1|                 N|         138|          79|           1|       49.2|  6.0|    0.5|       0.0|        6.94|                  1.0|       67.89|                 2.5|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:28:24|  2025-01-01 00:52:22|              1|         12.2|         1|                 N|         138|          35|           1|       48.5| 7.75|    0.5|     11.55|         0.0|                  1.0|        69.3|                 0.0|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:57:11|  2025-01-01 01:22:09|              2|         9.74|         1|                 N|         138|         235|           2|       42.9|  6.0|    0.5|       0.0|        6.94|                  1.0|       59.09|                 0.0|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:49:54|  2025-01-01 01:05:50|              1|          7.7|         1|                 N|         138|         263|           1|       30.3|10.25|    0.5|       9.8|        6.94|                  1.0|       58.79|                 2.5|       1.75|               0.0|\n",
            "|       1| 2025-01-01 00:21:10|  2025-01-01 00:37:59|              1|          9.6|         1|                 N|         138|         229|           1|       37.3|10.25|    0.5|      10.0|        6.94|                  1.0|       65.99|                 2.5|       1.75|               0.0|\n",
            "|       2| 2025-01-01 00:54:22|  2025-01-01 01:14:51|              4|          9.3|         4|                 N|         132|         265|           1|       47.1|  1.0|    0.5|      9.92|         0.0|                  1.0|       61.27|                 0.0|       1.75|               0.0|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Filter for rows that meet BOTH conditions using AND operator (&)\n",
        "# Airport_fee must be greater than 0 AND pickup time must be after specified time\n",
        "# Note: Must use & (bitwise AND) not 'and', and wrap conditions in parentheses\n",
        "spark_df.filter((spark_df['Airport_fee']>0) & (spark_df['tpep_pickup_datetime']> '2025-01-01 00:11:59')).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPC3QF_4SBEh",
        "outputId": "01a8f6db-a226-4b63-b653-1656d448cf47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+---------------+------------+\n",
            "|VendorId|passenger_count|total_amount|\n",
            "+--------+---------------+------------+\n",
            "|       2|              3|         9.7|\n",
            "|       2|              3|         8.3|\n",
            "|       2|              3|        19.2|\n",
            "|       1|              3|        22.7|\n",
            "|       1|              3|       15.45|\n",
            "|       2|              3|       30.13|\n",
            "|       2|              4|       50.76|\n",
            "|       2|              4|       29.76|\n",
            "|       2|              4|       16.13|\n",
            "|       1|              4|       37.95|\n",
            "|       2|              9|      111.32|\n",
            "|       2|              4|        23.4|\n",
            "|       1|              4|        12.2|\n",
            "|       2|              4|       36.48|\n",
            "|       1|              3|       12.29|\n",
            "|       2|              4|       28.08|\n",
            "|       1|              4|        16.4|\n",
            "|       2|              3|       56.38|\n",
            "|       2|              3|        34.8|\n",
            "|       1|              4|       17.15|\n",
            "+--------+---------------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Combine multiple operations: filter, select, and display\n",
        "# Step 1: Filter for rides with more than 2 passengers\n",
        "# Step 2: Select only VendorId, passenger_count, and total_amount columns\n",
        "# Step 3: Display the results\n",
        "spark_df.filter(spark_df['passenger_count']>2)\\\n",
        ".select(['VendorId','passenger_count','total_amount'])\\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsRwEFbdSBSd",
        "outputId": "99a0b9ec-4cc5-4eef-c693-8b660283cddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-----------+\n",
            "|passenger_count|Airport_fee|\n",
            "+---------------+-----------+\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "|              1|        0.0|\n",
            "+---------------+-----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Challenge: Write a query combining sort, select, and filter\n",
        "# Find non-airport rides with exactly 1 passenger, sort and show relevant columns\n",
        "# Step 1: Filter for Airport_fee == 0 (non-airport) AND passenger_count == 1\n",
        "# Step 2: Sort by Airport_fee\n",
        "# Step 3: Select only passenger_count and Airport_fee columns\n",
        "spark_df.filter((spark_df['Airport_fee']==0) & (spark_df['passenger_count']==1))\\\n",
        ".sort('Airport_fee')\\\n",
        ".select('passenger_count','Airport_fee')\\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qRhEAjZSBY5",
        "outputId": "c78c1ecf-22e7-4c96-d135-bb6139034475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+------------+\n",
            "|trip_distance|total_amount|\n",
            "+-------------+------------+\n",
            "|          1.6|        18.0|\n",
            "|          0.5|       12.12|\n",
            "|          0.6|        12.1|\n",
            "|         0.52|         9.7|\n",
            "|         0.66|         8.3|\n",
            "|         2.63|        24.1|\n",
            "|          0.4|       11.75|\n",
            "|          1.6|        19.1|\n",
            "|          2.8|        27.1|\n",
            "|         1.71|        16.4|\n",
            "|         2.29|        16.4|\n",
            "|         0.56|       12.96|\n",
            "|         1.99|        19.2|\n",
            "|          1.1|        12.9|\n",
            "|          3.2|        38.9|\n",
            "|          2.5|        22.7|\n",
            "|          1.9|       25.55|\n",
            "|         0.71|       -8.54|\n",
            "|         0.71|        12.2|\n",
            "|          1.2|        20.6|\n",
            "+-------------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Challenge: Select only trip distance and total_amount columns\n",
        "spark_df.select(['trip_distance', 'total_amount']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOf49DGNSBdx",
        "outputId": "42ebe269-ac29-4694-91fc-fc758a2f0528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+------------+\n",
            "|trip_distance|total_amount|\n",
            "+-------------+------------+\n",
            "|    276423.57|         5.0|\n",
            "|    276099.95|       13.88|\n",
            "|    222167.49|       35.94|\n",
            "|    206137.99|       29.64|\n",
            "|    202771.63|       14.85|\n",
            "|    189687.43|       17.45|\n",
            "|    181139.99|       11.08|\n",
            "|    168079.57|        4.49|\n",
            "|    167452.94|        5.45|\n",
            "|    164959.95|       18.05|\n",
            "|    158925.09|       14.82|\n",
            "|    156037.94|       33.49|\n",
            "|    143712.27|       12.51|\n",
            "|    135116.83|       36.52|\n",
            "|    134033.15|       22.89|\n",
            "|    124083.23|        15.0|\n",
            "|    121799.97|       31.88|\n",
            "|    121555.16|        8.46|\n",
            "|    118927.12|        3.68|\n",
            "|    118435.89|       19.59|\n",
            "+-------------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Challenge: Sort the resulting dataframe by trip distance in descending order\n",
        "# Shows longest trips first\n",
        "spark_df.select(['trip_distance', 'total_amount'])\\\n",
        ".sort(\"trip_distance\", ascending=False).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU9zYsUZSBja",
        "outputId": "b29b3418-b844-4eea-8cb6-4033d1a2944f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+------------+\n",
            "|trip_distance|total_amount|\n",
            "+-------------+------------+\n",
            "|      44730.3|        45.0|\n",
            "|      44684.1|       54.94|\n",
            "|      33588.9|        30.0|\n",
            "|      11187.2|       61.94|\n",
            "|      2001.95|       19.35|\n",
            "|      1847.61|       43.37|\n",
            "|      1472.37|       20.58|\n",
            "|        265.9|      139.14|\n",
            "|       255.33|     2506.71|\n",
            "|       206.45|      243.32|\n",
            "|        199.3|        19.0|\n",
            "|       188.88|      1311.7|\n",
            "|        181.9|       39.94|\n",
            "|       150.11|      501.75|\n",
            "|        148.3|      549.91|\n",
            "|       122.77|        64.7|\n",
            "|       119.66|      794.82|\n",
            "|       114.25|       396.0|\n",
            "|       105.24|       361.2|\n",
            "|       104.21|      249.53|\n",
            "+-------------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Combined challenge problem: Filter, Select, Sort\n",
        "# Find all non-airport solo rides and show them sorted by distance (longest first)\n",
        "spark_df.filter((spark_df['Airport_fee']==0) & (spark_df['passenger_count']==1))\\\n",
        ".select('trip_distance', 'total_amount')\\\n",
        ".sort('trip_distance', ascending=False)\\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWRHRGAXYxEz"
      },
      "outputs": [],
      "source": [
        "# Import necessary functions for missing value detection\n",
        "from pyspark.sql.functions import col, isnull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Data Cleaning and Missing Values\n",
        "\n",
        "### 12. Detecting and Handling Missing Values\n",
        "\n",
        "**Missing Data in DataFrames:**\n",
        "- Missing values are represented as `NULL` in Spark\n",
        "- Can skew analysis and cause errors in computations\n",
        "- Must be identified and handled appropriately\n",
        "\n",
        "**The `isnull()` Function:**\n",
        "- Returns True where values are NULL\n",
        "- Often combined with `filter()` to count missing values\n",
        "- Can be used to create masks for data cleaning\n",
        "\n",
        "**Common Missing Value Strategies:**\n",
        "1. **Removal**: Delete rows with NULL values (loses data)\n",
        "2. **Imputation**: Fill with default, mean, median, or forward-filled values\n",
        "3. **Domain-specific**: Use business rules to fill values\n",
        "4. **Keep separate**: Mark and analyze NULL values separately\n",
        "\n",
        "**The `fillna()` Method:**\n",
        "- Replaces NULL values with specified values\n",
        "- Can use a dictionary to fill different columns differently\n",
        "- Returns a new DataFrame with filled values\n",
        "- Useful for imputation strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H77GQJJPaLgd",
        "outputId": "a09d9d9a-407e-4bde-9405-1f7fbade4036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count the number of NULL/missing values in the 'fare_amount' column\n",
        "# isnull() returns True for NULL values, count() counts them\n",
        "spark_df.filter(isnull(col('fare_amount'))).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvBD9aeCaUsN",
        "outputId": "d30b7e0f-d081-4c0c-91a1-a41450108498"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "540149"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count the number of NULL/missing values in the 'passenger_count' column\n",
        "spark_df.filter(isnull(col('passenger_count'))).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq9fakAUaqk5"
      },
      "outputs": [],
      "source": [
        "# Fill missing values in 'passenger_count' column with default value of 1\n",
        "# This assumes if passenger count is missing, there was 1 passenger\n",
        "# Returns a new DataFrame with filled values\n",
        "df = spark_df.fillna({'passenger_count':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBwZfPYubNnc",
        "outputId": "f0248459-64a9-4e16-f293-5babc6e280df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify that missing values in 'passenger_count' have been filled\n",
        "# After fillna(), the count should be 0\n",
        "df.filter(isnull(col('passenger_count'))).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhSQmuFXd4V2"
      },
      "outputs": [],
      "source": [
        "# Import functions needed for feature engineering\n",
        "# unix_timestamp(): Convert datetime to seconds since epoch\n",
        "# round(): Round numerical values to specified decimal places\n",
        "from pyspark.sql.functions import unix_timestamp, round"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 13. Feature Engineering - Creating New Columns\n",
        "\n",
        "**What is Feature Engineering?**\n",
        "- Process of creating new features (columns) from existing data\n",
        "- Transforms raw data into meaningful features for analysis\n",
        "- Critical step in data preprocessing and machine learning\n",
        "\n",
        "**The `withColumn()` Method:**\n",
        "- Adds a new column to a DataFrame or modifies existing ones\n",
        "- Returns a new DataFrame with the added/modified column\n",
        "- Accepts column name and expression\n",
        "- Can chain multiple `withColumn()` calls\n",
        "\n",
        "**Common PySpark Functions:**\n",
        "- `unix_timestamp()`: Converts datetime to Unix timestamp (seconds since 1970)\n",
        "- `round()`: Rounds numerical values to specified decimal places\n",
        "- String functions: concat, substring, length, upper, lower\n",
        "- Math functions: abs, sqrt, pow, etc.\n",
        "- Date functions: year, month, day, hour, minute\n",
        "\n",
        "**Example: Trip Duration Calculation**\n",
        "- Extract pickup and dropoff times\n",
        "- Convert to Unix timestamps\n",
        "- Calculate difference in seconds\n",
        "- Convert to minutes and round"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU8X71qdbJek",
        "outputId": "fe012e0d-e1e7-494f-e8dd-634b10fc3ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+\n",
            "|trip_duration|\n",
            "+-------------+\n",
            "|          8.4|\n",
            "|          2.6|\n",
            "|          2.0|\n",
            "|          5.6|\n",
            "|          3.5|\n",
            "|         20.0|\n",
            "|          1.5|\n",
            "|         12.4|\n",
            "|         19.7|\n",
            "|          9.6|\n",
            "|          7.6|\n",
            "|          3.4|\n",
            "|         13.0|\n",
            "|          6.7|\n",
            "|         34.1|\n",
            "|         18.3|\n",
            "|         16.9|\n",
            "|          5.6|\n",
            "|          5.6|\n",
            "|         17.0|\n",
            "+-------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Feature Engineering: Create a new column 'trip_duration' in minutes\n",
        "# Step 1: Convert dropoff time to Unix timestamp (seconds)\n",
        "# Step 2: Convert pickup time to Unix timestamp (seconds)\n",
        "# Step 3: Calculate difference in seconds\n",
        "# Step 4: Divide by 60 to convert to minutes\n",
        "# Step 5: Round to 1 decimal place\n",
        "# withColumn() creates a new DataFrame with the added column\n",
        "df1 = df.withColumn('trip_duration', \\\n",
        "      round((unix_timestamp('tpep_dropoff_datetime') - unix_timestamp('tpep_pickup_datetime')) / 60, 1))\n",
        "df1.select('trip_duration').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85f375aa",
        "outputId": "44ff2431-7d2f-463d-8fb5-c47c7ae3cb4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "117"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data Quality Check: Count negative trip durations\n",
        "# Negative values indicate data issues (dropoff before pickup)\n",
        "# This helps identify potential data quality problems\n",
        "df1.filter(df1['trip_duration'] < 0).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1dea6af"
      },
      "source": [
        "### Data Quality Analysis - Negative Trip Duration Check\n",
        "\n",
        "**What does this check tell us?**\n",
        "\n",
        "If the count of negative `trip_duration` values is **zero**:\n",
        "-  All trip durations are positive or zero\n",
        "-  Indicates the calculation is accurate in terms of time order\n",
        "-  No data quality issues detected\n",
        "-  Pickup times are correctly recorded before dropoff times\n",
        "\n",
        "If there are **negative values**:\n",
        "-  Implies data quality issues\n",
        "-  Drop-off time recorded before pick-up time (impossible for valid trips)\n",
        "-  Might indicate:\n",
        "  - Incorrect timestamp recording\n",
        "  - System clock issues during data capture\n",
        "  - Data entry errors\n",
        "  - Records that need investigation and possible removal\n",
        "\n",
        "**How to Handle Negative Durations:**\n",
        "1. Filter them out for analysis (treat as invalid records)\n",
        "2. Investigate the source data for systematic issues\n",
        "3. Apply business logic (e.g., if duration < some threshold, mark as suspicious)\n",
        "4. Consider removing outliers and anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLnbnhtyfnN9",
        "outputId": "0c86ad83-3458-4306-edd8-9383faea3bfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+-----------+\n",
            "|        pu_datetime|        do_datetime|ride-amount|\n",
            "+-------------------+-------------------+-----------+\n",
            "|2025-01-01 00:18:38|2025-01-01 00:26:59|       10.0|\n",
            "|2025-01-01 00:32:40|2025-01-01 00:35:13|        5.1|\n",
            "|2025-01-01 00:44:04|2025-01-01 00:46:01|        5.1|\n",
            "|2025-01-01 00:14:27|2025-01-01 00:20:01|        7.2|\n",
            "|2025-01-01 00:21:34|2025-01-01 00:25:06|        5.8|\n",
            "|2025-01-01 00:48:24|2025-01-01 01:08:26|       19.1|\n",
            "|2025-01-01 00:14:47|2025-01-01 00:16:15|        4.4|\n",
            "|2025-01-01 00:39:27|2025-01-01 00:51:51|       12.1|\n",
            "|2025-01-01 00:53:43|2025-01-01 01:13:23|       19.1|\n",
            "|2025-01-01 00:00:02|2025-01-01 00:09:36|       11.4|\n",
            "|2025-01-01 00:20:28|2025-01-01 00:28:04|       11.4|\n",
            "|2025-01-01 00:33:58|2025-01-01 00:37:23|        5.8|\n",
            "|2025-01-01 00:42:40|2025-01-01 00:55:38|       14.2|\n",
            "|2025-01-01 00:30:07|2025-01-01 00:36:48|        7.9|\n",
            "|2025-01-01 00:39:55|2025-01-01 01:13:59|       26.1|\n",
            "|2025-01-01 00:16:54|2025-01-01 00:35:12|       17.7|\n",
            "|2025-01-01 00:43:10|2025-01-01 01:00:03|       16.3|\n",
            "|2025-01-01 00:01:41|2025-01-01 00:07:14|       -7.2|\n",
            "|2025-01-01 00:01:41|2025-01-01 00:07:14|        7.2|\n",
            "|2025-01-01 00:33:12|2025-01-01 00:50:14|       15.6|\n",
            "+-------------------+-------------------+-----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ],
      "source": [
        "# Rename columns for clarity and consistency\n",
        "# Step 1: Select specific columns\n",
        "# Step 2: Rename them using withColumnsRenamed()\n",
        "#   - 'tpep_pickup_datetime'  'pu_datetime' (shorter, clearer)\n",
        "#   - 'tpep_dropoff_datetime'  'do_datetime' (shorter, clearer)\n",
        "#   - 'fare_amount'  'ride-amount' (alternative naming)\n",
        "# This creates a new DataFrame with renamed columns\n",
        "df2 = df1.select('tpep_pickup_datetime','tpep_dropoff_datetime','fare_amount')\\\n",
        ".withColumnsRenamed({'tpep_pickup_datetime':'pu_datetime','tpep_dropoff_datetime':'do_datetime', 'fare_amount':'ride-amount'})\n",
        "\n",
        "df2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### 14. Renaming Columns\n",
        "\n",
        "**The `withColumnsRenamed()` Method:**\n",
        "- Renames one or more columns in a DataFrame\n",
        "- Takes a dictionary mapping old names to new names\n",
        "- Useful for:\n",
        "  - Standardizing column naming conventions\n",
        "  - Simplifying long or unclear column names\n",
        "  - Preparing data for downstream analysis\n",
        "  - Making data more readable and accessible\n",
        "- Returns a new DataFrame with renamed columns\n",
        "\n",
        "**Use Cases:**\n",
        "- Shortening verbose column names\n",
        "- Converting naming conventions (snake_case to camelCase, etc.)\n",
        "- Making column names more domain-friendly\n",
        "- Standardizing across multiple data sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OMLGB3kiNGn"
      },
      "source": [
        "---\n",
        "\n",
        "## Summary of Key PySpark Concepts\n",
        "\n",
        "### Transformations (Lazy) vs Actions (Eager)\n",
        "\n",
        "**Transformations** - Create new DataFrames, don't execute immediately:\n",
        "- `select()` - Choose columns\n",
        "- `filter()` - Subset rows\n",
        "- `sort()` - Order rows\n",
        "- `withColumn()` - Add/modify columns\n",
        "- `fillna()` - Replace NULL values\n",
        "- `withColumnsRenamed()` - Rename columns\n",
        "\n",
        "**Actions** - Execute computations and return results:\n",
        "- `show()` - Display data\n",
        "- `count()` - Count rows\n",
        "- `collect()` - Get all data\n",
        "- `first()` - Get first row\n",
        "- `describe()` - Statistics summary\n",
        "- `write()` - Save data\n",
        "\n",
        "### Performance Tips\n",
        "\n",
        "1. **Filter early** - Reduce data size before other operations\n",
        "2. **Select only needed columns** - Reduces memory usage\n",
        "3. **Combine operations** - Spark optimizes operation chains\n",
        "4. **Use appropriate data types** - Affects performance and storage\n",
        "5. **Handle missing values** - Prevents errors in calculations\n",
        "6. **Monitor partitioning** - Affects parallel processing efficiency\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. Always inspect data first (schema, sample rows, statistics)\n",
        "2. Check for and handle missing values\n",
        "3. Use meaningful column names\n",
        "4. Validate transformations with small samples before full data\n",
        "5. Document your data processing logic\n",
        "6. Keep transformations modular and readable\n",
        "7. Test edge cases and data quality issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
